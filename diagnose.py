#!/usr/bin/env python3
"""è¯Šæ–­è„šæœ¬ - æ£€æŸ¥å·¥ä½œæµçŠ¶æ€"""
import json
import requests
from pathlib import Path

# è¯»å–é…ç½®
with open('config.json', 'r', encoding='utf-8') as f:
    config = json.load(f)

n8n_url = config['n8n']['url'].rstrip('/')
api_key = config['n8n']['api_key']
repo_path = Path(config['git']['repo_path'])

headers = {
    'X-N8N-API-KEY': api_key,
    'Accept': 'application/json'
}

print("=" * 70)
print("n8n å·¥ä½œæµçŠ¶æ€è¯Šæ–­")
print("=" * 70)

# 1. æ£€æŸ¥ n8n API è¿”å›çš„å·¥ä½œæµ
print("\nã€1ã€‘n8n API è¿”å›çš„å·¥ä½œæµï¼š")
print("-" * 70)
try:
    response = requests.get(f"{n8n_url}/api/v1/workflows", headers=headers, timeout=10)
    response.raise_for_status()
    workflows = response.json()['data']

    print(f"æ€»æ•°: {len(workflows)} ä¸ª\n")
    for i, w in enumerate(workflows, 1):
        active_status = "âœ“ å¯ç”¨" if w.get('active') else "âœ— åœç”¨"
        print(f"{i}. {w['name']}")
        print(f"   ID: {w['id']}")
        print(f"   çŠ¶æ€: {active_status}")
        print(f"   æ›´æ–°æ—¶é—´: {w.get('updatedAt', 'N/A')}")
        print()

except Exception as e:
    print(f"âœ— é”™è¯¯: {e}")
    workflows = []

# 2. æ£€æŸ¥å¤‡ä»½è®°å½•
print("\nã€2ã€‘å¤‡ä»½è®°å½• (.workflow_data.json)ï¼š")
print("-" * 70)
data_file = repo_path / '.workflow_data.json'
if data_file.exists():
    try:
        with open(data_file, 'r', encoding='utf-8') as f:
            old_workflows = json.load(f)

        print(f"æ€»æ•°: {len(old_workflows)} ä¸ª\n")
        for i, (wid, wdata) in enumerate(old_workflows.items(), 1):
            print(f"{i}. {wdata.get('name', 'Unknown')}")
            print(f"   ID: {wid}")
            print()
    except Exception as e:
        print(f"âœ— è¯»å–é”™è¯¯: {e}")
        old_workflows = {}
else:
    print("âœ— æ–‡ä»¶ä¸å­˜åœ¨ (é¦–æ¬¡è¿è¡Œ)")
    old_workflows = {}

# 3. æ£€æŸ¥æœ¬åœ°å¤‡ä»½æ–‡ä»¶
print("\nã€3ã€‘æœ¬åœ°å¤‡ä»½æ–‡ä»¶ (workflows/ ç›®å½•)ï¼š")
print("-" * 70)
workflows_dir = repo_path / 'workflows'
if workflows_dir.exists():
    json_files = list(workflows_dir.glob('*.json'))
    print(f"æ€»æ•°: {len(json_files)} ä¸ª\n")
    for i, filepath in enumerate(sorted(json_files), 1):
        print(f"{i}. {filepath.name}")
else:
    print("âœ— ç›®å½•ä¸å­˜åœ¨")

# 4. æ¯”å¯¹åˆ†æ
print("\nã€4ã€‘æ¯”å¯¹åˆ†æï¼š")
print("-" * 70)

if workflows:
    current_ids = {w['id'] for w in workflows}
    old_ids = set(old_workflows.keys())

    # æ–°å¢çš„
    new_ids = current_ids - old_ids
    if new_ids:
        print(f"\nğŸ†• æ–°å¢çš„å·¥ä½œæµ ({len(new_ids)} ä¸ª):")
        for w in workflows:
            if w['id'] in new_ids:
                print(f"  - {w['name']} (ID: {w['id']})")

    # åˆ é™¤çš„
    deleted_ids = old_ids - current_ids
    if deleted_ids:
        print(f"\nğŸ—‘ï¸ å·²åˆ é™¤çš„å·¥ä½œæµ ({len(deleted_ids)} ä¸ª):")
        for wid in deleted_ids:
            wname = old_workflows[wid].get('name', 'Unknown')
            print(f"  - {wname} (ID: {wid})")

    # ç›¸åŒçš„
    same_ids = current_ids & old_ids
    if same_ids:
        print(f"\nâœ“ æœªå˜æ›´çš„å·¥ä½œæµ ({len(same_ids)} ä¸ª):")
        for w in workflows:
            if w['id'] in same_ids:
                print(f"  - {w['name']} (ID: {w['id']})")

    if not new_ids and not deleted_ids:
        print("\nâœ“ n8n å’Œå¤‡ä»½è®°å½•ä¸€è‡´ï¼Œæ— å˜æ›´")

print("\n" + "=" * 70)
print("è¯Šæ–­å®Œæˆ")
print("=" * 70)
